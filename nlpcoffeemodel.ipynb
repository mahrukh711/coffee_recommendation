{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7359bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coffee Analysis Columns: Index(['name', 'roaster', 'roast', 'loc_country', 'origin_1', 'origin_2',\n",
      "       '100g_USD', 'rating', 'review_date', 'desc_1', 'desc_2', 'desc_3'],\n",
      "      dtype='object')\n",
      "Coffee Clean Columns: Index(['slug', 'all_text', 'rating', 'roaster', 'name', 'location', 'origin',\n",
      "       'roast', 'est_price', 'review_date', 'agtron', 'aroma', 'acid', 'body',\n",
      "       'flavor', 'aftertaste', 'with_milk', 'desc_1', 'desc_2', 'desc_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the datasets\n",
    "coffeeAnalysis = pd.read_csv(r\"C:\\Users\\Shafqat\\Desktop\\coffee\\coffee_analysis.csv\")\n",
    "coffeeClean = pd.read_csv(r\"C:\\Users\\Shafqat\\Desktop\\coffee\\coffee_clean.csv\")\n",
    "\n",
    "# Check initial shapes and columns\n",
    "print(\"Coffee Analysis Columns:\", coffeeAnalysis.columns)\n",
    "print(\"Coffee Clean Columns:\", coffeeClean.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81c1d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Coffee Analysis Columns: Index(['name', 'roaster_x', 'roast_x', 'loc_country', 'origin_1', 'origin_2',\n",
      "       '100g_USD', 'rating_x', 'review_date_x', 'desc_1_x', 'desc_2_x',\n",
      "       'desc_3_x', 'slug', 'all_text', 'rating_y', 'roaster_y', 'location',\n",
      "       'origin', 'roast_y', 'est_price', 'review_date_y', 'agtron', 'aroma',\n",
      "       'acid', 'body', 'flavor', 'aftertaste', 'with_milk', 'desc_1_y',\n",
      "       'desc_2_y', 'desc_3_y'],\n",
      "      dtype='object')\n",
      "                      name                   roaster_x       roast_x  \\\n",
      "0       Ethiopia Suke Quto                 Roast House  Medium-Light   \n",
      "1       Ethiopia Suke Quto                 Roast House  Medium-Light   \n",
      "2       Ethiopia Suke Quto      Indaba Coffee Roasters  Medium-Light   \n",
      "3       Ethiopia Suke Quto      Indaba Coffee Roasters  Medium-Light   \n",
      "4  Ethiopia Kayon Mountain  Red Rooster Coffee Roaster         Light   \n",
      "\n",
      "     loc_country              origin_1       origin_2  100g_USD  rating_x  \\\n",
      "0  United States             Guji Zone  Oromia Region      4.19        92   \n",
      "1  United States             Guji Zone  Oromia Region      4.19        92   \n",
      "2  United States             Guji Zone  Oromia Region      4.70        93   \n",
      "3  United States             Guji Zone  Oromia Region      4.70        93   \n",
      "4  United States  Odo Shakiso District      Guji Zone      5.14        93   \n",
      "\n",
      "   review_date_x                                           desc_1_x  ...  \\\n",
      "0  November 2017  Delicate, sweetly spice-toned. Pink peppercorn...  ...   \n",
      "1  November 2017  Delicate, sweetly spice-toned. Pink peppercorn...  ...   \n",
      "2    August 2020  Brightly fruit-toned, deeply sweet-tart. Pomeg...  ...   \n",
      "3    August 2020  Brightly fruit-toned, deeply sweet-tart. Pomeg...  ...   \n",
      "4  November 2017  Delicate, richly and sweetly tart. Dried hibis...  ...   \n",
      "\n",
      "  agtron aroma acid body  flavor aftertaste with_milk  \\\n",
      "0  62/80   9.0  9.0  8.0     9.0        8.0       NaN   \n",
      "1  58/74   9.0  8.0  9.0     9.0        8.0       NaN   \n",
      "2  62/80   9.0  9.0  8.0     9.0        8.0       NaN   \n",
      "3  58/74   9.0  8.0  9.0     9.0        8.0       NaN   \n",
      "4  59/76   9.0  9.0  8.0     9.0        8.0       NaN   \n",
      "\n",
      "                                            desc_1_y  \\\n",
      "0  Crisply sweet, citrusy-bright. Tangerine zest,...   \n",
      "1  Brightly fruit-toned, deeply sweet-tart. Pomeg...   \n",
      "2  Crisply sweet, citrusy-bright. Tangerine zest,...   \n",
      "3  Brightly fruit-toned, deeply sweet-tart. Pomeg...   \n",
      "4  Crisp, richly sweet. Cocoa nib, dried nectarin...   \n",
      "\n",
      "                                            desc_2_y  \\\n",
      "0  This coffee tied for the second-highest rating...   \n",
      "1  Southern Ethiopia coffees like this one are la...   \n",
      "2  This coffee tied for the second-highest rating...   \n",
      "3  Southern Ethiopia coffees like this one are la...   \n",
      "4  Produced by the Hassen family at their estate ...   \n",
      "\n",
      "                                            desc_3_y  \n",
      "0  A balanced, juicy washed-process Ethiopia cup ...  \n",
      "1  A cleanly fruit-forward natural-process Ethiop...  \n",
      "2  A balanced, juicy washed-process Ethiopia cup ...  \n",
      "3  A cleanly fruit-forward natural-process Ethiop...  \n",
      "4  A juicy-sweet, balanced Ethiopia natural chara...  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the datasets on 'name' column\n",
    "coffeeAnalysis = coffeeAnalysis.merge(coffeeClean, on='name', how='inner')\n",
    "print(\"Merged Coffee Analysis Columns:\", coffeeAnalysis.columns)\n",
    "print(coffeeAnalysis.head())  # Inspect merged data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14ecc209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns retained for processing: ['name', 'origin_1', 'origin_2', 'origin', 'aroma', 'acid', 'body', 'flavor', 'aftertaste', 'with_milk']\n"
     ]
    }
   ],
   "source": [
    "# Required columns (check dynamically for their existence)\n",
    "required_columns = [\n",
    "    'name', 'roaster', 'roast', 'origin_1', 'origin_2', 'rating', \n",
    "    'desc_1', 'desc_2', 'desc_3', 'origin', 'aroma', 'acid', 'body', \n",
    "    'flavor', 'aftertaste', 'with_milk', 'tags'\n",
    "]\n",
    "\n",
    "# Filter for existing columns\n",
    "existing_columns = [col for col in required_columns if col in coffeeAnalysis.columns]\n",
    "print(f\"Columns retained for processing: {existing_columns}\")\n",
    "\n",
    "# Keep only available columns\n",
    "coffeeAnalysis = coffeeAnalysis[existing_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8310056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "coffeeAnalysis.dropna(inplace=True)\n",
    "\n",
    "# Process description columns\n",
    "for desc_col in ['desc_1', 'desc_2', 'desc_3']:\n",
    "    if desc_col in coffeeAnalysis.columns:\n",
    "        coffeeAnalysis[desc_col] = coffeeAnalysis[desc_col].apply(lambda x: x.split() if isinstance(x, str) else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b3fefff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 'tags' column after creation:\n",
      "                                           name tags\n",
      "1708  Ethiopia Guji Natural Euphora Special Lot   []\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Dynamically select columns for 'tags'\n",
    "tag_columns = ['name', 'roaster', 'roast', 'origin', 'origin_1', 'origin_2', \n",
    "               'rating', 'desc_1', 'desc_2', 'desc_3', 'aroma', 'acid', \n",
    "               'body', 'flavor', 'aftertaste', 'with_milk']\n",
    "existing_tag_columns = [col for col in tag_columns if col in coffeeAnalysis.columns]\n",
    "\n",
    "# Create the 'tags' column by concatenating valid columns\n",
    "coffeeAnalysis['tags'] = coffeeAnalysis.apply(\n",
    "    lambda row: sum([row[col] for col in existing_tag_columns if isinstance(row[col], list)], []),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verify if 'tags' is populated\n",
    "print(\"Sample 'tags' column after creation:\")\n",
    "print(coffeeAnalysis[['name', 'tags']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "834cb7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of new_df:\n",
      "                                           name  \\\n",
      "1708  Ethiopia Guji Natural Euphora Special Lot   \n",
      "\n",
      "                                           origin tags  \n",
      "1708  Guji Zone, Oromia Region, Southern Ethiopia       \n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare a new DataFrame with selected columns\n",
    "required_columns = ['name', 'roaster', 'origin', 'tags']\n",
    "existing_columns = [col for col in required_columns if col in coffeeAnalysis.columns]\n",
    "\n",
    "# Ensure 'tags' exists and is populated\n",
    "if 'tags' not in coffeeAnalysis.columns or coffeeAnalysis['tags'].isnull().all():\n",
    "    raise ValueError(\"The 'tags' column is either missing or empty. Check the tag creation step.\")\n",
    "\n",
    "# Create a copy of the DataFrame with the existing columns\n",
    "new_df = coffeeAnalysis[existing_columns].copy()\n",
    "\n",
    "# Safely join 'tags' lists into a single string and convert to lowercase\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x).lower() if isinstance(x, list) else \"\")\n",
    "\n",
    "# Verify the content of new_df\n",
    "print(\"Preview of new_df:\")\n",
    "print(new_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2b061b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Ethopia':\n",
      "No recommendations found for coffee: Ethopia\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stems(text):\n",
    "    \"\"\"Apply stemming to the input text.\"\"\"\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])\n",
    "\n",
    "# Apply stemming to the 'tags' column\n",
    "new_df['tags'] = new_df['tags'].apply(stems)\n",
    "\n",
    "# Ensure no empty tags before applying CountVectorizer\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: x if x.strip() != \"\" else \"no description\")\n",
    "\n",
    "# Convert the 'tags' column to vectors using CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vector = cv.fit_transform(new_df['tags']).toarray()\n",
    "\n",
    "# Calculate cosine similarity between the vectorized tags\n",
    "similarity = cosine_similarity(vector)\n",
    "\n",
    "# Recommendation function\n",
    "def recommend(coffee_name):\n",
    "    \"\"\"Provide recommendations for a given coffee name.\"\"\"\n",
    "    try:\n",
    "        index = new_df[new_df['name'] == coffee_name].index[0]\n",
    "        distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "        \n",
    "        recommendations = []\n",
    "        for i in distances[1:6]:  # Top 5 recommendations\n",
    "            recommendations.append(new_df.iloc[i[0]]['name'])\n",
    "        \n",
    "        return recommendations\n",
    "    except IndexError:\n",
    "        return [f\"No recommendations found for coffee: {coffee_name}\"]\n",
    "\n",
    "# Example usage\n",
    "coffee_to_recommend = 'Ethopia'  # Replace with an actual coffee name from the dataset\n",
    "recommendations = recommend(coffee_to_recommend)\n",
    "\n",
    "print(f\"Recommendations for '{coffee_to_recommend}':\")\n",
    "for coffee in recommendations:\n",
    "    print(coffee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79f7ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and similarity matrix have been saved to 'artificates' directory.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save the DataFrame and similarity matrix using pickle\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create the 'artifacts' directory if it doesn't exist\n",
    "os.makedirs('artificates', exist_ok=True)\n",
    "\n",
    "# Save the new_df DataFrame and similarity matrix\n",
    "pickle.dump(new_df, open('artificates/coffeeAnalysis_list.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('artificates/similarity.pkl', 'wb'))\n",
    "\n",
    "# Confirm the files are saved\n",
    "print(\"Data and similarity matrix have been saved to 'artificates' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52063cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    coffee_name = pd.read_pickle('artificates/coffeeAnalysis_list.pkl')\n",
    "    print(\"File loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ade49916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('artificates/coffeeAnalysis_list.pkl', 'rb') as file:\n",
    "    coffee_name = pickle.load(file, encoding='latin1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
